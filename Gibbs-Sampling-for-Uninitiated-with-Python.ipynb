{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Gibbs Sampler for the Uninitiated with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"table-of-contents\">Table of Contents</a>\n",
    "1. [Introduction](#introduction)\n",
    "2. [Hyperparameters and Random Variables in Codes](#hyperparameters-and-random-variables)\n",
    "\n",
    "Go to [The end](#the-end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"introduction\">1. Introduction</a> (Back to [Table of Contents](#table-of-contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This article is inspired by the _masterpiece_ of [**Gibbs Sampling tutorial**](https://maranathaedu-my.sharepoint.com/:b:/g/personal/hendra_bunyamin_it_maranatha_edu/EZA9beLgBdZPip9br-UrdSAB024P8IBGESYAbJP3MfRQFQ?e=HdMzZ9) by _Resnik and Hardisty_ and also an _awesome_ [**github repo**](https://github.com/bobflagg/gibbs-sampling-for-the-uninitiated) by _Bob Flagg_.      \n",
    "Both of these resources are excellent and highly recommended for anyone to read.\n",
    "\n",
    "This article will show a step by step implementation of a Gibbs sampler for a Naive Bayes model in Python.    \n",
    "Let us start with the problem definition. Assume that we would like to classify whether or not the sentiment of a document is either $0$ (negative) or $1$ (positive) visualized by the following image.\n",
    "<img src=\"sentiment-positive-negative.jpeg\" alt=\"Drawing\" style=\"width: 550px;\"/>([_image source_](https://towardsdatascience.com/cnn-sentiment-analysis-1d16b7c5a0e7))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, the image below is the generative story of how the documents are generated as explained in $\\S$2.1 of the paper.   \n",
    "<img src=\"naive-bayes-graphical-model.png\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recall some of the notations from the paper. There are $6$ variables in the image. We shall discuss these one by one.     \n",
    "\n",
    "$\\pmb{\\gamma_\\pi}$ is a _vectorized version of hyperparameters_ from a **Beta** distribution. In the literature (Gelman et al., 2014), these hyperparameters usually are represented by $\\alpha$ and $\\beta$. In the paper, they are $\\gamma_{\\pi0}$ and $\\gamma_{\\pi1}$. Specifically, $\\pmb{\\gamma_\\pi}$ is defined as follows:        \n",
    "$$\\begin{equation}\n",
    "    \\pmb{\\gamma_\\pi} = \\begin{bmatrix} \\gamma_{\\pi0} \\\\ \\gamma_{\\pi1} \\end{bmatrix}.\n",
    "\\end{equation} \\tag{1}\\label{eq:gamma-pi}$$    \n",
    "    \n",
    "Secondly, $\\pi$ is a random variable which has a **Beta** distribution, in other words \n",
    "$$\\begin{equation}\n",
    "    \\pi \\sim \\text{Beta}(\\gamma_{\\pi0}, \\gamma_{\\pi1}) \\tag{2}\\label{eq:beta}. \n",
    "\\end{equation}$$\n",
    "             \n",
    "Thirdly, $L_j$ is a random variable for $j$th document which has a **Bernoulli** distribution, \n",
    "$$\\begin{equation}\n",
    "    L_j \\sim \\text{Bernoulli}(\\pi) \\tag{3}\\label{eq:binomial}. \n",
    "\\end{equation}$$     \n",
    "    \n",
    "Fourthly, $\\pmb{\\gamma_{\\theta}}$ is a hyperparameter vector whose dimension is **the size of vocabulary** ($V$) and provided for a **Dirichlet** distribution. In the literature (Gelman et al., 2014), these hyperparameters usually are represented by $\\alpha_1$, $\\alpha_2$, $\\ldots$, $\\alpha_V$. In the paper, it is defined as a vector defined as follows: \n",
    "\n",
    "$$ \\begin{equation}\n",
    "    \\pmb{\\gamma_{\\theta}} = \\begin{bmatrix} \n",
    "            \\gamma_{\\theta1} \\\\\n",
    "            \\gamma_{\\theta2} \\\\\n",
    "            \\vdots \\\\\n",
    "            \\gamma_{\\theta V}\n",
    "        \\end{bmatrix} = \\begin{bmatrix} \n",
    "            1 \\\\\n",
    "            1 \\\\\n",
    "            \\vdots \\\\\n",
    "            1\n",
    "        \\end{bmatrix} \\tag{4}\\label{eq:gamma-theta}. \n",
    "\\end{equation}\n",
    "$$\n",
    "   \n",
    "Fifthly, $\\pmb{\\theta}$ is a vector which contains two random variables, $\\theta_0$ and $\\theta_1$. Specifically, both $\\theta_0$ and $\\theta_1$ are **Dirichlet** distributions with $\\pmb{\\gamma_{\\theta}}$ as their hyperparameters,\n",
    "$$\\begin{align}\n",
    "    \\theta_0 &\\sim \\text{Dirichlet}(\\pmb{\\gamma_{\\theta}}) \\tag{5}\\label{eq:dirichlet-1}, \\\\\n",
    "    \\theta_1 &\\sim \\text{Dirichlet}(\\pmb{\\gamma_{\\theta}}) \\tag{6}\\label{eq:dirichlet-2}.         \n",
    "\\end{align}$$     \n",
    "\n",
    "Last but not least, $\\pmb{W}_j$ represents a probability distribution of $j$th document which modeled by a **Multinomial** distribution. As the $j$th document has $R_j$ words and probabilities of each word in the vocabulary, the **Multinomial** distribution is stated as follows:\n",
    "$$ \\begin{equation}\n",
    "    \\pmb{W}_j \\sim \\text{Multinomial}(R_j, \\theta_{L_j}), \\text{ for }j = 1, \\ldots, N. \\tag{7}\\label{eq:multinomial}\n",
    "\\end{equation}$$\n",
    "\n",
    "\n",
    "Hopefully, now that we know what those variables are, we can move forward by programming them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries\n",
    "import numpy as np\n",
    "from numpy.random import beta, binomial, dirichlet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"hyperparameters-and-random-variables\">2. Hyperparameters and Random Variables in Codes</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the latent variable $\\pi$ can be integrated out (see $\\S$2.4.3 of the paper), the state of the model at an iteration step is determined by current values of variables, as follows: \n",
    "1. the predicted labels $\\pmb{L}$, in code $\\Rightarrow$ `L` with the size (`num_docs`,)     \n",
    "2. the topics $\\bf \\theta_0$ and $\\bf \\theta_1$, in code $\\Rightarrow$ `theta`, \n",
    "3. for each word $k$, the number of times it occurs is $W_{jk}$ (in code, `W`),\n",
    "4. the number of documents labelled $0$, $C_0$ (in code `C[0]`), and \n",
    "5. the number of documents labelled $1$, $C_1$ (in code `C[1]`).    \n",
    "\n",
    "Let us sample the labels (`L`) for `N` documents with hyperparameters, $\\gamma_{\\pi}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Priority apples | Second priority | Third priority |\n",
    "|-------|--------|---------|\n",
    "| ambrosia | gala | red delicious |\n",
    "| pink lady | jazz | macintosh |\n",
    "| honeycrisp | granny smith | fuji |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Paper| Code | Dimension of the variables      |\n",
    "|-------|-------|-------        |\n",
    "|$\\pmb{L}$|`L` | $\\# \\text{docs} \\times 1$ |     \n",
    "|$\\mathcal{N}_{\\mathbb{C}}$|`L` | $\\# \\text{docs} \\times 1$ |     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample labels for all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_labels(N, gamma_pi):\n",
    "    '''\n",
    "    Sample labels for N documents according to Beta distribution with hyperparameters=gamma_pi\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: int\n",
    "        number of documents        \n",
    "    gamma_pi: list with len=2\n",
    "        hyperparameters of the Beta distribution        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    array with shape (N,)\n",
    "        Labels for the N documents\n",
    "    '''\n",
    "    # pi is the Beta distribution with \n",
    "    pi = beta(gamma_pi[0], gamma_pi[1])\n",
    "    \n",
    "    return binomial(1, pi, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================================================================================\n",
    "#       DEMO for sample labels\n",
    "# \n",
    "# In this demo, we sample 5 labels for 5 documents, with alpha = 1 and beta = 1; this is just a uniform\n",
    "# distribution\n",
    "# =========================================================================================================\n",
    "sample_labels(5, [1,1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, the this state will be represented as a dictionary\n",
    "with the following keys: 'L' for the predicted labels, 'theta' for the topics, 'cnts' for word counts and 'C' \n",
    "for document counts.\n",
    "\n",
    "How to initialize our sampler is described in at the end of $\\S$2.3 of the paper:\n",
    "1. Pick a value $\\pi$ by sampling from the Beta($\\gamma_{\\pi1}$, $\\gamma_{\\pi0}$) distribution. \n",
    "2. Then, for each $j$, flip a coin with success probability $\\pi$, and assign the label $L_j$ of document \n",
    "   $j$ based on the outcome of the coin flip.\n",
    "3. Pick values for $\\theta_0$ and $\\theta_1$ by sampling from Dirichlet($\\gamma_{\\theta}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sample_labels` function is used to create labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEGIN: MWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = dirichlet([1,1,1,1,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62871943, 0.11657468, 0.03541088, 0.0595411 , 0.1597539 ],\n",
       "       [0.23815068, 0.21171132, 0.05286869, 0.23091282, 0.26635648]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END: MWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import multinomial, poisson\n",
    "\n",
    "def generate_data(N, gamma_pi, gamma_theta, lmbda):\n",
    "    labels = sample_labels(N, gamma_pi)\n",
    "    theta = dirichlet(gamma_theta, 2)\n",
    "    W = []\n",
    "    for l in labels:\n",
    "        R = poisson(lmbda)\n",
    "        doc = multinomial(R, theta[l]) # What is this?\n",
    "        W.append({(i, c) for i,c in enumerate(doc) if c > 0}) # c is the frequency of i-th word\n",
    "        # W.append({(i, c) for i,c in enumerate(doc) })        \n",
    "    return W, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEGIN: MWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06287367, 0.22362438, 0.32989322, 0.25471872, 0.12889002],\n",
       "       [0.10268955, 0.00178593, 0.21901684, 0.2698463 , 0.4066614 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_theta = [1] * 5 \n",
    "theta = dirichlet(gamma_theta,2)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = poisson(25)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 12, 10,  5,  3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = multinomial(R, theta[0])\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{(0, 5), (1, 12), (2, 10), (3, 5), (4, 3)}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#W.append({(i, c) for i,c in enumerate(doc) if c > 0})\n",
    "W.append({(i, c) for i,c in enumerate(doc)})\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{(0, 4), (2, 2), (3, 2), (4, 2)}, {(0, 7), (1, 2), (3, 2)}], array([1, 0]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_pi = (1, 1)\n",
    "gamma_theta = [1] * 5 # with vocabulary size = 5 \n",
    "generate_data(2, gamma_pi, gamma_theta, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END:MWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{(0, 1), (3, 2), (4, 5), (2, 2)}, {(2, 7), (4, 2), (3, 2)}, {(0, 3), (3, 1), (4, 6)}, {(4, 5), (3, 1), (2, 2)}, {(0, 1), (4, 11)}]\n",
      "\n",
      "[0 1 0 0 0]\n",
      "\n",
      "[4, 3, 3, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "#       DEMO for generate_data\n",
    "# \n",
    "# In this demo, we construct gamma_phi, gamma_theta, and lmbda as inputs to the function\n",
    "# =================================================================\n",
    "N = 5\n",
    "gamma_pi = (1, 1)\n",
    "gamma_theta = [1] * 5 # with vocabulary size = 5 \n",
    "lmbda = 10\n",
    "\n",
    "W, labels = generate_data(N, gamma_pi, gamma_theta, lmbda)\n",
    "print(W)\n",
    "print()\n",
    "print(labels)\n",
    "print()\n",
    "doc_length = []\n",
    "for doc in W:\n",
    "    doc_length.append(len(doc))\n",
    "print(doc_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(W, labels, gamma_pi, gamma_theta):\n",
    "    N = len(W)\n",
    "    M = len(labels)\n",
    "    V = len(gamma_theta)\n",
    "\n",
    "    L = sample_labels(N - M, gamma_pi) # We only sample the unobserved instances\n",
    "    theta = dirichlet(gamma_theta, 2)\n",
    "\n",
    "    C = np.zeros((2,))\n",
    "    C += gamma_pi\n",
    "    cnts = np.zeros((2, V))\n",
    "    cnts += gamma_theta\n",
    "    \n",
    "    for d, l in zip(W, labels.tolist() + L.tolist()):\n",
    "        for i, c in d: \n",
    "            cnts[l][i] += c\n",
    "        C[l] += 1\n",
    "\n",
    "    return {'C':C, 'N':cnts, 'L':L, 'theta':theta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "#       DEMO for initialize(W, labels, gamma_pi, gamma_theta):\n",
    "# =================================================================\n",
    "state = initialize(W, labels, gamma_pi, gamma_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEGIN: MWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{(0, 1), (2, 2), (3, 2), (4, 5)},\n",
       " {(2, 7), (3, 2), (4, 2)},\n",
       " {(0, 3), (3, 1), (4, 6)},\n",
       " {(2, 2), (3, 1), (4, 5)},\n",
       " {(0, 1), (4, 11)}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.,  1.,  5.,  5., 28.],\n",
       "       [ 1.,  1.,  8.,  3.,  3.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([3., 4.]), 'N': array([[13., 11.,  2.,  2.,  1.],\n",
      "       [ 4.,  5., 13.,  8., 11.]]), 'L': array([], dtype=int64), 'theta': array([[0.31126237, 0.01444759, 0.06135053, 0.16568939, 0.44725012],\n",
      "       [0.16831418, 0.06627954, 0.00070647, 0.22677274, 0.53792706]])}\n"
     ]
    }
   ],
   "source": [
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END: MWE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The update step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation (49) on page 16 states\n",
    "\n",
    "$$\n",
    "    \\begin{equation}\n",
    "        \\text{Pr(L}_j = x | \\mathbf{L}^{(-j)}, \\mathbb{C}^{(-j)}, \\mathbf{\\theta_0}, \\mathbf{\\theta_1}; \\mathbf{\\mu}) = \\frac{C_x + \\gamma_{\\pi x} - 1}{N + \\gamma_{\\pi 1} + \\gamma_{\\pi 0} - 1} \\prod_{i=1}^{V}{\\theta_{x,i}^{\\text{W}_{ji}}}\n",
    "    \\end{equation}\n",
    "$$\n",
    "\n",
    "In code below,      \n",
    "$\\text{Pr(L}_j = x | \\mathbf{L}^{(-j)}, \\mathbb{C}^{(-j)}, \\mathbf{\\theta_0}, \\mathbf{\\theta_1}; \\mathbf{\\mu})$ = `pi`      \n",
    "$C_x + \\gamma_{\\pi x} - 1$ = `C[l]`,     \n",
    "$N + \\gamma_{\\pi 1} + \\gamma_{\\pi 0} - 1$ = `d`   \n",
    "$\\text{W}_{ji}$ = `c`      \n",
    "$\\theta_{0,i}$ = `theta[0,i]`    \n",
    "$\\theta_{1,i}$ = `theta[1,i]`    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(state, X):\n",
    "    C = state['C']\n",
    "    N = state['N']\n",
    "    L = state['L']\n",
    "    theta = state['theta']\n",
    "    \n",
    "    # Update the labels for all documents:\n",
    "    for j, l in enumerate(L):\n",
    "        \n",
    "        # Drop document j from the corpus:\n",
    "        # Note: X is a list of sets\n",
    "        \n",
    "        # ======================================================================================================\n",
    "        #    Substract j's word counts from the total word counts of whatever class it's currently a member of\n",
    "        # ======================================================================================================\n",
    "        for i, c in X[j]: \n",
    "            N[l][i] -= c\n",
    "            \n",
    "        # ===============================================================\n",
    "        #     Subtract 1 from the count of documents with label L_j\n",
    "        # ===============================================================\n",
    "        C[l] -= 1  \n",
    "        \n",
    "        # Compute the conditional probability that L[j] = 1:  \n",
    "        if C[0] == 1: # What will happen if there is only one or zero document which has label 0?\n",
    "            pi = 1.0\n",
    "        elif C[1] == 1 <= 0: \n",
    "            pi = 0.0 \n",
    "        else:\n",
    "            # compute the product of probabilities (sum of logs)\n",
    "            d = np.sum(C) - 1\n",
    "            value0 = np.log((C[0] - 1.0) / d)\n",
    "            value1 = np.log((C[1] - 1.0) / d)\n",
    "            for i, c in X[j]:\n",
    "                value0 += c * np.log(theta[0,i])\n",
    "                value1 += c * np.log(theta[1,i])\n",
    "            m = max(value0, value1)\n",
    "            value0 = np.exp(value0 - m) # an exemplary technique\n",
    "            value1 = np.exp(value1 - m) \n",
    "            pi = value1 / (value0 + value1)\n",
    "            \n",
    "        # Sample the new label from the conditional probability:\n",
    "        l = binomial(1, pi)\n",
    "        L[j] = l\n",
    "        # Add document j back into the corpus:\n",
    "        C[l] += 1\n",
    "        for i, c in X[j]: \n",
    "            N[l][i] += c\n",
    "    #print('--->>>', np.min(cnts[0]), np.min(cnts[1]))\n",
    "    \n",
    "    # Update the topics:\n",
    "    # as described in page 17 Equation (51)\n",
    "    # ------------------------------------------\n",
    "    theta[0] = dirichlet(N[0])\n",
    "    theta[1] = dirichlet(N[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "for indeks in range(10):\n",
    "    l = binomial(1, 0)\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0\n",
    "if C == 1 <= 0:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sampler(W, labels, iterations, gamma_pi, gamma_theta):\n",
    "    state = initialize(W, labels, gamma_pi, gamma_theta)\n",
    "    \n",
    "    # We take only the unobserved instances as we would like to make predictions\n",
    "    X = W[len(labels):]   \n",
    "    \n",
    "    # Let's iterate\n",
    "    for t in range(iterations): \n",
    "        update(state, X)\n",
    "        if t % 25 == 0:\n",
    "            print('Iteration:', t, 'with size of X', len(X))\n",
    "    return state['L']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEGIN: MWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".8 * 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Manjeet', 4, 40), ('Nikhil', 1, 50), ('Shambhavi', 3, 60), ('Astha', 2, 70)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================\n",
    "#    DEMO: zip()\n",
    "# =======================\n",
    "# initializing lists \n",
    "name = [ \"Manjeet\", \"Nikhil\", \"Shambhavi\", \"Astha\" ] \n",
    "roll_no = [ 4, 1, 3, 2 ] \n",
    "marks = [ 40, 50, 60, 70 ] \n",
    "  \n",
    "# using zip() to map values \n",
    "mapped = zip(name, roll_no, marks) \n",
    "list(mapped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# DEMO: \n",
    "# 1. Generate Dataset, \n",
    "# 2. Define train and test set\n",
    "# 3. Initialize State\n",
    "# 4. \n",
    "# ============================================\n",
    "#  We generate 20 documents\n",
    "N = 15\n",
    "gamma_pi = (1, 1)\n",
    "gamma_theta = [1] * 5 # with vocabulary size = 5 \n",
    "lmbda = 10\n",
    "\n",
    "W, labels = generate_data(N, gamma_pi, gamma_theta, lmbda)\n",
    "\n",
    "# define number of iterations\n",
    "iterations = 50\n",
    "\n",
    "# Divide the dataset into train:80% and test: 20%\n",
    "n = int(N * 0.8)   \n",
    "labels_observed = labels[:n]    # 16 instances \n",
    "labels_unobserved = labels[n:]  # 4 instances \n",
    "\n",
    "# ==========================\n",
    "#   Inside Run_Sampler\n",
    "# ==========================\n",
    "\n",
    "# Initialize the state with all the prerequisites\n",
    "state = initialize(W, labels_observed, gamma_pi, gamma_theta)\n",
    "\n",
    "# Take all unobserved instances which we would like to predict\n",
    "X = W[len(labels_observed):]\n",
    "\n",
    "# Let us update the state!\n",
    "\n",
    "# Take all documents which consists of label 0 and label 1\n",
    "C = state['C']\n",
    "\n",
    "# Take all word frequencies from each label: 0 and 1 with vocabulary size = 5\n",
    "N = state['N']\n",
    "\n",
    "# Take all labels\n",
    "L = state['L']\n",
    "\n",
    "# the the theta which is a dirichlet distribution with parameter gamma_theta\n",
    "theta = state['theta']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{(0, 2), (2, 1), (3, 3)},\n",
       " {(0, 1), (2, 2), (3, 6), (4, 3)},\n",
       " {(2, 2), (3, 8), (4, 1)}]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13570209, 0.18180046, 0.48193175, 0.13410703, 0.06645867],\n",
       "       [0.10755363, 0.62616666, 0.1724669 , 0.08765726, 0.00615555]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2., 15.])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 4., 3., 2., 3.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{(0, 1), (1, 6), (2, 1), (3, 2), (4, 2)},\n",
       " {(1, 1), (2, 2), (3, 2), (4, 1)},\n",
       " {(0, 1), (1, 3), (2, 1)},\n",
       " {(0, 3), (1, 4), (2, 2), (3, 1)},\n",
       " {(0, 2), (1, 5), (3, 2)},\n",
       " {(1, 5), (2, 4), (3, 2)},\n",
       " {(0, 1), (1, 2), (2, 2), (4, 4)},\n",
       " {(1, 3), (4, 3)},\n",
       " {(0, 4), (1, 5), (2, 1), (3, 1), (4, 2)},\n",
       " {(0, 1), (2, 1), (3, 1), (4, 1)},\n",
       " {(1, 7), (4, 1)},\n",
       " {(0, 1), (1, 3), (2, 2), (3, 1), (4, 3)},\n",
       " {(0, 1), (1, 3), (2, 2), (3, 1), (4, 2)},\n",
       " {(0, 1), (1, 4), (2, 3), (4, 4)},\n",
       " {(1, 5), (2, 1), (3, 1), (4, 1)}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(labels_observed) + list(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1), (1, 4), (2, 3), (4, 4)}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.,  3.,  2.,  3.],\n",
       "       [16., 54., 21., 14., 23.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END: MWE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(L_true, L_predicted):\n",
    "    correct = 0\n",
    "    for i, l in enumerate(L_predicted):\n",
    "        if L_true[i] == l: correct += 1\n",
    "    accuracy = float(correct)/len(L_predicted)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(V, N, gamma_pi, gamma_theta, lmbda):\n",
    "    W, labels = generate_data(N, gamma_pi, gamma_theta, lmbda)\n",
    "    iterations = 100\n",
    "    \n",
    "    # Divide the dataset into train:80% and test: 20%\n",
    "    n = int(N * 0.8)\n",
    "    labels_observed = labels[:n]\n",
    "    labels_unobserved = labels[n:]\n",
    "    \n",
    "    # Pass all the ingredients \n",
    "    L = run_sampler(W, labels_observed, iterations, gamma_pi, gamma_theta)\n",
    "    return compute_accuracy(labels_unobserved, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 with size of X 80\n",
      "Iteration: 25 with size of X 80\n",
      "Iteration: 50 with size of X 80\n",
      "Iteration: 75 with size of X 80\n",
      "Iteration: 0 with size of X 80\n",
      "Iteration: 25 with size of X 80\n",
      "Iteration: 50 with size of X 80\n",
      "Iteration: 75 with size of X 80\n",
      "Iteration: 0 with size of X 80\n",
      "Iteration: 25 with size of X 80\n",
      "Iteration: 50 with size of X 80\n",
      "Iteration: 75 with size of X 80\n",
      "Iteration: 0 with size of X 80\n",
      "Iteration: 25 with size of X 80\n",
      "Iteration: 50 with size of X 80\n",
      "Iteration: 75 with size of X 80\n",
      "Iteration: 0 with size of X 80\n",
      "Iteration: 25 with size of X 80\n",
      "Iteration: 50 with size of X 80\n",
      "Iteration: 75 with size of X 80\n",
      "Iteration: 0 with size of X 80\n",
      "Iteration: 25 with size of X 80\n",
      "Iteration: 50 with size of X 80\n",
      "Iteration: 75 with size of X 80\n",
      "Iteration: 0 with size of X 80\n",
      "Iteration: 25 with size of X 80\n",
      "Iteration: 50 with size of X 80\n",
      "Iteration: 75 with size of X 80\n",
      "Iteration: 0 with size of X 80\n",
      "Iteration: 25 with size of X 80\n",
      "Iteration: 50 with size of X 80\n",
      "Iteration: 75 with size of X 80\n",
      "Iteration: 0 with size of X 80\n",
      "Iteration: 25 with size of X 80\n",
      "Iteration: 50 with size of X 80\n",
      "Iteration: 75 with size of X 80\n",
      "Iteration: 0 with size of X 80\n",
      "Iteration: 25 with size of X 80\n",
      "Iteration: 50 with size of X 80\n",
      "Iteration: 75 with size of X 80\n",
      "Accuracy results: 0.812, 0.850, 0.875, 0.838, 0.925, 0.762, 0.863, 0.912, 0.838, 0.850\n",
      "Average accuracy = 0.853\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAM0ElEQVR4nO3dXWie533H8e+vsjND1qbOosGwvSZsziJHbOsmskINi9MWnBzYJ2XYUPaCqE8W72BlkKGRZBk5WHtQmDHdzByyFaws68EmhkcGm0bRaIoVugXHxiC8FwsPojYmYxQvjvnvwEqqyI/03HIeWdHl7wcMuu/70vP8D8I3t6/nxakqJEmb38c2egBJ0mAYdElqhEGXpEYYdElqhEGXpEYYdElqRN+gJ3khyZtJzq5wPUn+JMlckteT/NLgx5Qk9dPlDv1FYP8q1x8Hdi/+OQJ848OPJUlaq75Br6pvA2+tsuQg8Jd1w6vAJ5P81KAGlCR1s2UAj7EDuLTkeH7x3H8vX5jkCDfu4rn77rt/+aGHHhrA00vSneO11177flUN97o2iKCnx7me3ydQVSeAEwBjY2M1Ozs7gKeXpDtHkv9c6dog3uUyD+xacrwTuDyAx5UkrcEggj4F/Priu10+A7xdVTdtt0iS1lffLZckk8CjwH1J5oFngK0AVfWnwGngCWAO+CHwW+s1rCRpZX2DXlWH+1wv4LcHNpEk6Zb4SVFJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRp0eTkJKOjowwNDTE6Osrk5ORGjyStySC+bVHa9CYnJ5mYmODkyZPs3buXmZkZxsfHATh8eNUPS0sfGbnxyf3bz6/P1UfJ6Ogox44dY9++fe+fm56e5ujRo5w92/NfX5Q2RJLXqmqs5zWDLsHQ0BBXr15l69at75+7du0a27Zt4/r16xs4mfRBqwXdPXQJGBkZYWZm5gPnZmZmGBkZ2aCJpLVzD13NS3r9o1o3e+yxxz7U72/U33al93iHruZVVac/p06d4uGHHwbg4Ycf5tSpU51/15jro8A9dGmZJAZaH1nuoUvSHcCgS1IjDLokNcKgS1IjDLokNcKgS1Ij/GCRNpV7772XK1eurPvzdP0w0Yexfft23nrrrXV/Ht05DLo2lStXrjTzHvHb8T8N3VnccpGkRhh0SWqEQZekRriHrk2lnvkEPHvPRo8xEPXMJzZ6BDXGoGtTyR/+T1MvitazGz2FWuKWiyQ1wjt0bTqtvN1v+/btGz2CGmPQtancju0Wvw9dm5VbLpLUCIMuSY0w6JLUiE5BT7I/yYUkc0me6nH9p5NMJ/lekteTPDH4UaVbk2RNf27ld1p5oVabW98XRZMMAceBLwDzwJkkU1V1bsmyPwBerqpvJNkDnAbuX4d5pTXzBU7dKbrcoT8CzFXVxap6B3gJOLhsTQHvfeztHuDy4EaUJHXRJeg7gEtLjucXzy31LPClJPPcuDs/2uuBkhxJMptkdmFh4RbGlSStpEvQe20OLv877GHgxaraCTwBfDPJTY9dVSeqaqyqxoaHh9c+rSRpRV2CPg/sWnK8k5u3VMaBlwGq6jvANuC+QQwoSeqmS9DPALuTPJDkLuAQMLVszX8BnwNIMsKNoLunIkm3Ud+gV9W7wJPAK8B5bryb5Y0kzyU5sLjsK8CXk/wbMAn8ZvnWAkm6rTq9D72qTlfVg1X1M1X1/OK5p6tqavHnc1X12ar6har6xar6h/UcWloPk5OTjI6OMjQ0xOjoKJOTkxs9krQmfjmXxI2YT0xMcPLkSfbu3cvMzAzj4+MAHD58eIOnk7rJRu2MjI2N1ezs7IY8t7Tc6Ogox44dY9++fe+fm56e5ujRo5w9e3YDJ5M+KMlrVTXW85pBl2BoaIirV6+ydevW989du3aNbdu2cf369Q2cTPqg1YLul3NJwMjICDMzMx84NzMzw8jIyAZNJK2dQZeAiYkJxsfHmZ6e5tq1a0xPTzM+Ps7ExMRGjyZ15ouiEj964fPo0aOcP3+ekZERnn/+eV8Q1abiHrokbSLuoUvSHcCgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNaJT0JPsT3IhyVySp1ZY82tJziV5I8mpwY4pSepnS78FSYaA48AXgHngTJKpqjq3ZM1u4PeBz1bVlSQ/uV4DS5J663KH/ggwV1UXq+od4CXg4LI1XwaOV9UVgKp6c7BjSpL66RL0HcClJcfzi+eWehB4MMm/JHk1yf5eD5TkSJLZJLMLCwu3NrEkqacuQU+Pc7XseAuwG3gUOAz8eZJP3vRLVSeqaqyqxoaHh9c6qyRpFV2CPg/sWnK8E7jcY83fVtW1qvp34AI3Ai9Juk26BP0MsDvJA0nuAg4BU8vW/A2wDyDJfdzYgrk4yEElSavrG/Sqehd4EngFOA+8XFVvJHkuyYHFZa8AP0hyDpgGfq+qfrBeQ0uSbpaq5dvht8fY2FjNzs5uyHNL0maV5LWqGut1zU+KSlIjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjOgU9yf4kF5LMJXlqlXVfTFJJxgY3oiSpi75BTzIEHAceB/YAh5Ps6bHu48DvAN8d9JCSpP663KE/AsxV1cWqegd4CTjYY90fAV8Frg5wPklSR12CvgO4tOR4fvHc+5J8GthVVX+32gMlOZJkNsnswsLCmoeVJK2sS9DT41y9fzH5GPB14Cv9HqiqTlTVWFWNDQ8Pd59SktRXl6DPA7uWHO8ELi85/jgwCvxzkv8APgNM+cKoJN1eXYJ+Btid5IEkdwGHgKn3LlbV21V1X1XdX1X3A68CB6pqdl0mliT11DfoVfUu8CTwCnAeeLmq3kjyXJID6z2gJKmbLV0WVdVp4PSyc0+vsPbRDz+WJGmt/KSoJDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIzoFPcn+JBeSzCV5qsf1301yLsnrSf4xyacGP6okaTV9g55kCDgOPA7sAQ4n2bNs2feAsar6eeBbwFcHPagkaXVd7tAfAeaq6mJVvQO8BBxcuqCqpqvqh4uHrwI7BzumJKmfLkHfAVxacjy/eG4l48Df97qQ5EiS2SSzCwsL3aeUJPXVJejpca56Lky+BIwBX+t1vapOVNVYVY0NDw93n1KS1NeWDmvmgV1LjncCl5cvSvJ5YAL41ar6v8GMJ0nqqssd+hlgd5IHktwFHAKmli5I8mngz4ADVfXm4MeUJPXTN+hV9S7wJPAKcB54uareSPJckgOLy74G/Djw10n+NcnUCg8nSVonXbZcqKrTwOll555e8vPnBzyXJGmN/KSoJDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDWiU9CT7E9yIclckqd6XP+xJH+1eP27Se4f9KCSpNX1DXqSIeA48DiwBzicZM+yZePAlar6WeDrwB8PelBJ0uq63KE/AsxV1cWqegd4CTi4bM1B4C8Wf/4W8LkkGdyYkqR+tnRYswO4tOR4HviVldZU1btJ3gZ+Avj+0kVJjgBHFg//N8mFWxlaWmf3sey/Xekj5FMrXegS9F532nULa6iqE8CJDs8pbZgks1U1ttFzSGvVZctlHti15HgncHmlNUm2APcAbw1iQElSN12CfgbYneSBJHcBh4CpZWumgN9Y/PmLwD9V1U136JKk9dN3y2VxT/xJ4BVgCHihqt5I8hwwW1VTwEngm0nmuHFnfmg9h5bWmduC2pTijbQktcFPikpSIwy6JDXCoEuLkryQ5M0kZzd6FulWGHTpR14E9m/0ENKtMujSoqr6Nn5+QpuYQZekRhh0SWqEQZekRhh0SWqEQZcWJZkEvgP8XJL5JOMbPZO0Fn70X5Ia4R26JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXi/wEpaUtnfbpE6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "V = 10000\n",
    "N = 400\n",
    "gamma_pi = (1, 1)\n",
    "gamma_theta = [1] * V\n",
    "lmbda = 25\n",
    "\n",
    "results = []\n",
    "cnt = 0\n",
    "while cnt < 10:\n",
    "    accuracy = run_simulation(V, N, gamma_pi, gamma_theta, lmbda)\n",
    "    results.append(accuracy)\n",
    "    cnt += 1\n",
    "    \n",
    "print(\"Accuracy results: %s\" % \", \".join(\"%0.3f\" % x for x in results))\n",
    "print(\"Average accuracy = %0.3f\" % np.average(results))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylim([0,1])\n",
    "plt.boxplot(results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <a id=\"the-end\">The End</a> (Back to [Table of Contents](#table-of-contents))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
